---
title: "Multiple Systems Estimation"
author: "Michiel Bron"
format: html
editor: visual
---

## Multiple Systems Estimation.

First, we load the libraries we want to use:

```{r}
#| echo: false
#| include: false
library(tidyverse)
library(Rcapture)
source("./allib/estimation/multiple_estimate.R")
options(warn=-1)
```

```{python}
#| echo: false
#| include: false
import pandas as pd
import numpy as np
```

We can process the data in R as follows:

```{r}
path <- "results/hall/design_matrix_300.csv" 
df <- rasch.csv(path)
df
```

We will also load the data in Python:

```{python}
df = pd.read_csv(r.path)
df
```

Some statistics:

```{r}
grouped <- df %>% group_by(positive) %>% summarise(sum = sum(count))
grouped
```

### RCapture

To use RCapture, we have to drop some columns.

```{r}
source("./allib/estimation/multiple_estimate.R")
rasch_to_abundance(df)
```

### Rasch Only Positive

Again, we have to adapt the dataframe; we have to drop some columns and rows.

```{r}
df.onlypos <- df %>% filter(positive == 1) %>% select(starts_with("learner") & !ends_with("positive"), matches("count"), starts_with("h") & ends_with("positive"))
df.onlypos
```

Below, the code for the determining the number of

```{r}
source("allib/estimation/rasch_estimate_bootstrap.R")
```

We execute the model here:

```{r}
options(warn=-1)
rasch.parametric(df.onlypos)
```

We can also execute this in Python

```{python}
from allib.estimation.rasch_multiple import rasch_estimate_only_pos

only_pos_res = rasch_estimate_only_pos(df, 8911)
only_pos_res[0]
```

### Rasch Positive and Negative

Gegeven een ingevulde design-matrix met data genereerd door $l$ learners.

**Procedure:**

1.  In initiële *E-step*, papers in willekeurige aantallen over de twee ontbrekende cellen. Stel aantal papers in stapel is 2.000. Stel op een bepaald moment zijn er 30 hits en 20 niet hits. Verdeel dan willekeurig 1.950 over de twee cellen. Merk op dat tellingen optellen tot 2.000.
2.  In *M-step*, fit log-lineair model op p $2^l$ cellen voor hits en op $2^l$ cellen voor niet-hits in *E-step*, gebruik fitted values uit *M-step* om 1.950 opnieuw te verdelen.
3.  En ga dan op en neer tussen E- en M- step totdat het convergeert.

#### Initiele versie in Python gebaseerd op M. Cruyff

Gegeven een ingevulde design-matrix met data genereerd door $l$ learners.

1.  In initiële *E-step*, papers **50/50** over de twee ontbrekende cellen. Stel aantal papers in stapel is 2.000. Stel op een bepaald moment zijn er 30 hits en 20 niet hits. Verdeel dan **50/50** 1.950 over de twee cellen. Merk op dat tellingen optellen tot 2.000.
2.  In *M-step*, fit log-lineair model met de Newton-Rhapson functie op $2^l$ cellen voor hits en op $2^l$ cellen voor niet-hits in *E-step*, gebruik fitted values uit *M-step* om 1.950 opnieuw te verdelen.
3.  En ga dan op en neer tussen E- en M- step totdat het convergeert.

Puntschatting in R

```{r}
options(warn=-1)
source("allib/estimation/rasch_em_comb.R")
model.glm <- rasch.em.comb(df, 8911, 0.5)
glm.rasch.em <- rasch.em.horizon(df, 8911, 0.5)
model.nr <- rasch.ridge.em.comb(df, 8911, 0.5)
nr.rasch.em <- rasch.ridge.em.horizon(df, 8911, 0.5)
coefs_glm <- coef(model.glm)
coefs_nr <- model.nr$coefficients

```

```{r}
model.glm


```

```{python}
from allib.estimation.rasch_multiple import rasch_estimate

results = rasch_estimate(df, 8911, 0.5)
```

```{python}
results[0]
results[1].beta
```

```{python}
coef_data = {"glm": r.coefs_glm, "nr": r.coefs_nr[:,0], "nr_python": results[1].beta.tolist()}
pd.DataFrame.from_dict(coef_data)
```

```{python}
from allib.estimation.rasch_multiple import rasch_estimate_bf

results_bf = rasch_estimate_bf(df, 8911, 0.5)
results_bf
```

#### Bruteforce methode

Het aantal combinaties van mogelijke bijschattingen voor het aantal positieve en negatieve documenten is eindig. Stel er moeten nog 7000 documenten gelezen worden dan zijn de mogelijke combinaties van de bijschattingen als volgt.

$$[(1; 6999), (2; 6998), \ldots, (n; 7000 - n)]$$

Omdat in bepaalde situaties de bijschattingen voor het aantal positieve documenten erg hoog is, ontstond het vermoeden dat het EM-algoritme convergeert op een lokaal minimum in plaats van het globale minimum. Om dit aan te tonen, heb ik de curve van de deviance geplot aan de hand van alle mogelijke combinaties van de bijschattingen. Dit betreft een goede approximatie van de gehele zoekruimte, dus globale en lokale minima zouden zichtbaar moeten zijn.

```{r}
source("allib/estimation/rasch_bruteforce.R")
bf.results <- rasch.bf.comb(df, 8911)
table <- rasch.bf.table(bf.results)
ggplot(data=table) + aes(x=estimate,y=deviance) + geom_point()
```

Op bovenstaande plot zijn de globale en lokale minima goed zichtbaar. Vaak bevinden deze zich rond 7500 en tussen de 0 en de 20.

#### Methode met meerdere initiële schattingen

```{python}
from allib.estimation.rasch_multiple import rasch_estimate_parametric_no_fixed_proportion 

nfp_results = rasch_estimate_parametric_no_fixed_proportion(df, 8911)
```

```{python}
nfp_results[0]
```

#### Methode met initiële schatting gebaseerd op de Rasch Only Pos schatting

```{python}
from allib.estimation.rasch_multiple import rasch_estimate_parametric_init_by_pos

ibp_results = rasch_estimate_parametric_init_by_pos(df, 8911)
```

```{python}
ibp_results[0]
```
